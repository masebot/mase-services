<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <title>Large Language Models Explained | Learn | MASE Services</title>
    <meta name="description" content="The Technology Behind ChatGPT">
    <meta name="robots" content="index, follow">
    
    <meta property="og:title" content="Large Language Models Explained">
    <meta property="og:description" content="The Technology Behind ChatGPT">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://mase-services.com/learn/fundamentals/what-is-llm">
    
    <link rel="canonical" href="https://mase-services.com/learn/fundamentals/what-is-llm">
    
    <!-- Favicon -->
    <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-512.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/favicon-512.png">
    <meta property="og:image" content="https://mase-services.com/assets/icons/mase-og-image.png">
    
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Space+Grotesk:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        :root { --accent: #00f3ff; --bg: #030305; }
        body { background-color: var(--bg); color: white; font-family: 'Inter', sans-serif; }
        h1, h2, h3, h4 { font-family: 'Space Grotesk', sans-serif; }
        .accent { color: var(--accent); }
        .btn-primary { background: white; color: black; font-weight: 600; padding: 0.75rem 1.5rem; border-radius: 6px; transition: all 0.3s; text-decoration: none; display: inline-block; }
        .btn-primary:hover { background: var(--accent); }
        .inline-code { background: rgba(255,255,255,0.1); padding: 0.125rem 0.375rem; border-radius: 4px; font-family: monospace; font-size: 0.875em; }
        article a { color: var(--accent); }
        article a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <!-- Nav -->
    <nav class="border-b border-white/10 px-6 py-4">
        <div class="max-w-4xl mx-auto flex justify-between items-center">
            <a href="/" class="text-2xl font-bold tracking-tighter font-mono">MASE<span class="accent">_</span></a>
            <div class="flex items-center gap-6">
                <a href="/research" class="text-sm text-gray-400 hover:text-white transition">Research</a>
                <a href="/learn" class="text-sm text-gray-400 hover:text-white transition">Learn</a>
                <a href="/#section-contact" class="btn-primary text-sm py-2 px-4">Contact</a>
            </div>
        </div>
    </nav>

    <!-- Breadcrumb -->
    <div class="border-b border-white/10 px-6 py-3">
        <div class="max-w-4xl mx-auto">
            <nav class="text-sm text-gray-400">
                <a href="/" class="hover:text-white">Home</a>
                <span class="mx-2">/</span>
                <a href="/learn" class="hover:text-white">Learn</a>
                <span class="mx-2">/</span><a href="/learn/fundamentals" class="hover:text-white">Fundamentals</a>
                <span class="mx-2">/</span>
                <span class="text-white">Large Language Models Explained</span>
            </nav>
        </div>
    </div>

    <!-- Article Header -->
    <header class="py-12 px-6 border-b border-white/10">
        <div class="max-w-4xl mx-auto">
            <div class="text-sm font-mono mb-4" style="color: #00f3ff">FUNDAMENTALS</div>
            <h1 class="text-4xl md:text-5xl font-bold mb-4">Large Language Models Explained</h1>
            <p class="text-xl text-gray-400 mb-6">The Technology Behind ChatGPT</p>
            <div class="flex items-center gap-6 text-sm text-gray-400">
                <span class="flex items-center gap-2"><i data-lucide="clock" class="w-4 h-4"></i>14 min read</span>
                
            </div>
        </div>
    </header>

    <!-- Article Content -->
    <article class="py-12 px-6">
        <div class="max-w-4xl mx-auto prose-lg">
            <h1 class="text-3xl font-bold mb-8">Large Language Models Explained: The Technology Behind ChatGPT</h1>

<strong>Estimated read time: 14 minutes</strong>

<em>What every business leader needs to understand about the most transformative technology since the internet.</em>

<h2 class="text-2xl font-bold mt-12 mb-6">What Is a Large Language Model?</h2>

<p class="text-gray-300 leading-relaxed my-4">At its core, a large language model is a prediction machine. Specifically, it predicts the next word in a sequence.</p>

<p class="text-gray-300 leading-relaxed my-4">That's it. That's the fundamental operation. Given the text "The capital of France is," the model predicts that "Paris" should come next. Given "Dear Mr. Johnson, Thank you for your email regarding," it predicts words like "your," "the," or "our" as likely continuations.</p>

<p class="text-gray-300 leading-relaxed my-4">This sounds almost disappointingly simple. How does next-word prediction lead to a system that can write poetry, analyze legal contracts, debug code, and hold nuanced conversations?</p>

<p class="text-gray-300 leading-relaxed my-4">The answer lies in scale—and in what happens when you push next-word prediction to its mathematical extremes.</p>

<p class="text-gray-300 leading-relaxed my-4">To predict the next word accurately, a model must develop internal representations of how language works. To correctly continue "The Eiffel Tower is located in the city of," the model must implicitly understand that the Eiffel Tower is a structure, that structures have locations, that Paris is a city, and that the Eiffel Tower is specifically in Paris. The prediction task forces the model to build a rich internal model of the world—not because anyone programmed it to, but because that knowledge improves its predictions.</p>

<blockquote class="border-l-4 border-accent pl-6 py-2 my-8 text-xl italic text-gray-300"><strong>"The shocking discovery of modern AI is that prediction, at sufficient scale, becomes a form of understanding."</strong></blockquote>

<p class="text-gray-300 leading-relaxed my-4">This emergent understanding is what separates modern LLMs from the autocomplete on your phone. Your phone's autocomplete learns simple patterns: you often type "running" after "I'm." But it doesn't understand what running is, or why you might be doing it, or how to discuss the philosophy of exercise.</p>

<p class="text-gray-300 leading-relaxed my-4">Large language models, trained on hundreds of billions of words, develop something qualitatively different. They learn grammar and syntax, yes. But they also learn facts about the world, logical relationships between concepts, common reasoning patterns, literary styles, emotional nuances, and countless other aspects of human knowledge—all as byproducts of learning to predict words more accurately.</p>

<figure class="my-8"><img src="/assets/infographics/mase-infographic-how-llms-work.png" alt="How Large Language Models Work" class="w-full rounded-lg border border-white/10"><figcaption class="text-center text-sm text-gray-500 mt-2">How Large Language Models Work</figcaption></figure>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">How Scale Creates Capability</h2>

<p class="text-gray-300 leading-relaxed my-4">The "large" in large language model refers primarily to the number of <em>parameters</em>—the adjustable numerical values that define how the model processes information. Think of parameters as the model's internal configuration: billions of tiny dials that, collectively, encode everything the model has learned.</p>

<p class="text-gray-300 leading-relaxed my-4">GPT-3, released in 2020, contained 175 billion parameters. GPT-4, released in 2023, is rumored to contain over one trillion parameters (OpenAI has not confirmed exact numbers). Claude 3, Anthropic's flagship model, operates at similar scales. Google's Gemini Ultra represents a comparable investment in model size.</p>

<p class="text-gray-300 leading-relaxed my-4">To train these models, companies feed them staggering amounts of text. GPT-4 was reportedly trained on approximately 13 trillion tokens—roughly equivalent to 10 million books. The training data includes websites, books, scientific papers, code repositories, and countless other text sources.</p>

<p class="text-gray-300 leading-relaxed my-4">What happens when you scale up? Researchers have discovered something remarkable: capabilities emerge suddenly and unpredictably. A model that can't perform arithmetic at 10 billion parameters might suddenly develop arithmetic ability at 100 billion parameters. A model that produces garbled reasoning at one scale might produce coherent, step-by-step analysis at the next scale up.</p>

<p class="text-gray-300 leading-relaxed my-4">These "emergent capabilities" caught researchers by surprise. OpenAI, Google DeepMind, and Anthropic have all documented instances where scaling led to capabilities that weren't explicitly trained and weren't predicted by performance at smaller scales.</p>

<p class="text-gray-300 leading-relaxed my-4">The implication is profound: we don't fully understand why these models work as well as they do. We designed the training process, but the capabilities that emerged were not specifically programmed. This is simultaneously exciting and humbling—we've created something powerful that we don't entirely understand.</p>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">The Training Process: A Simple Explanation</h2>

<p class="text-gray-300 leading-relaxed my-4">Large language models are developed in three main phases, each building on the last.</p>

<h3 class="text-xl font-bold mt-10 mb-4">Phase 1: Pre-Training</h3>

<p class="text-gray-300 leading-relaxed my-4">Pre-training is where the model learns to predict words. The process works like this:</p>

<li class="ml-4">Take a massive corpus of text—essentially a large portion of the internet, plus books and other sources</li>
<li class="ml-4">For each passage, hide the next word and ask the model to predict it</li>
<li class="ml-4">When the model predicts incorrectly, adjust its parameters slightly to improve future predictions</li>
<li class="ml-4">Repeat trillions of times</li>

<p class="text-gray-300 leading-relaxed my-4">This process takes months on specialized hardware that costs tens of millions of dollars. But the result is a model with broad knowledge of language, facts, reasoning patterns, and even cultural context—all learned through the deceptively simple task of predicting what word comes next.</p>

<h3 class="text-xl font-bold mt-10 mb-4">Phase 2: Fine-Tuning</h3>

<p class="text-gray-300 leading-relaxed my-4">A pre-trained model is knowledgeable but not particularly useful. It will continue any text you give it, but it doesn't understand what you actually want. Ask it a question, and it might generate another question, or an advertisement, or continue in a completely irrelevant direction.</p>

<p class="text-gray-300 leading-relaxed my-4">Fine-tuning aligns the model with human intentions. Researchers create datasets of ideal responses: "Here's a question a user might ask, and here's how a helpful assistant should respond." The model is then trained on these examples, learning to produce the kinds of responses humans find useful.</p>

<p class="text-gray-300 leading-relaxed my-4">This phase is far cheaper than pre-training—hours rather than months—but it's crucial for transforming a word-predictor into an assistant.</p>

<h3 class="text-xl font-bold mt-10 mb-4">Phase 3: Reinforcement Learning from Human Feedback (RLHF)</h3>

<p class="text-gray-300 leading-relaxed my-4">The final phase refines the model's judgment through human feedback. The process works roughly like this:</p>

<li class="ml-4">Show the model a prompt and have it generate multiple possible responses</li>
<li class="ml-4">Have humans rank these responses from best to worst</li>
<li class="ml-4">Train a "reward model" that learns to predict human preferences</li>
<li class="ml-4">Use this reward model to further fine-tune the language model, encouraging responses that score higher</li>

<p class="text-gray-300 leading-relaxed my-4">This technique, pioneered by OpenAI and refined by Anthropic and others, is what makes modern chatbots feel conversational rather than mechanical. The model learns not just what's accurate, but what's helpful, clear, and appropriate.</p>

<p class="text-gray-300 leading-relaxed my-4">Anthropic has extended this approach with their "Constitutional AI" method, where models are trained to follow ethical principles and explain their reasoning—an attempt to make AI systems that are not just capable but aligned with human values.</p>

<blockquote class="border-l-4 border-accent pl-6 py-2 my-8 text-xl italic text-gray-300"><strong>"RLHF is how we teach machines what humans actually want—not just what they literally say."</strong></blockquote>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">Why LLMs Can Write, Analyze, and Converse</h2>

<p class="text-gray-300 leading-relaxed my-4">Given what we've discussed, the capabilities of LLMs become less mysterious.</p>

<strong>Writing</strong>: The models have learned, through exposure to billions of examples, what good writing looks like in countless contexts. They've absorbed the patterns of business memos, academic papers, marketing copy, poetry, and dialogue. When asked to write in a specific style, they draw on this vast implicit knowledge.

<strong>Analysis</strong>: To predict text accurately, models must understand logical relationships. They've seen millions of examples of arguments being constructed, evidence being evaluated, and conclusions being drawn. They can reproduce these patterns because they've learned them deeply.

<strong>Conversation</strong>: The models have been exposed to dialogue of every kind—customer service interactions, interviews, debates, casual conversations. Combined with RLHF training that rewards helpful and coherent responses, they've learned to maintain context, address questions, and engage in back-and-forth exchange.

<strong>Code</strong>: Programming languages are structured text with precise rules. Models trained on millions of code examples have learned syntax, common patterns, and even the logic of debugging—all through the same next-token prediction that powers their language abilities.

<p class="text-gray-300 leading-relaxed my-4">The key insight is that these aren't separate capabilities bolted onto a language model. They're all manifestations of the same underlying mechanism: sophisticated pattern matching and generation, learned from astronomical quantities of human-generated text.</p>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">How LLMs Differ from Other AI</h2>

<p class="text-gray-300 leading-relaxed my-4">It's easy to lump all AI together, but large language models represent a distinct approach with unique characteristics.</p>

<strong>Traditional Machine Learning</strong> typically trains specialized models for narrow tasks: this model detects spam, that model predicts customer churn, another classifies images. Each model is purpose-built and trained on task-specific data. LLMs, by contrast, are generalists—one model can write essays, translate languages, analyze sentiment, and answer factual questions.

<strong>Expert Systems</strong> from earlier AI eras used hand-coded rules created by human experts. They were brittle and required enormous manual effort. LLMs learn their rules automatically from data, making them more flexible and far less labor-intensive to develop.

<strong>Robotic Process Automation (RPA)</strong> follows exact scripted workflows. It can click this button, copy that field, paste it there. LLMs can handle ambiguity and variation—if a form field is in a slightly different location, an LLM can figure it out. But unlike RPA, LLMs may make mistakes in straightforward tasks.

<strong>Computer Vision and Speech Recognition</strong> models process images and audio. LLMs process text. Modern multimodal models like GPT-4 Vision and Gemini combine these capabilities, analyzing images and text together, representing a convergence of previously separate AI domains.

<p class="text-gray-300 leading-relaxed my-4">The distinctive power of LLMs lies in their generality. You don't need a different model for each task. One model, through careful prompting, can serve dozens of functions. This generality also means they're less specialized—a dedicated sentiment analysis model might outperform an LLM on that specific task. But the flexibility often outweighs the marginal performance loss.</p>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">What LLMs Excel At—and Where They Fail</h2>

<p class="text-gray-300 leading-relaxed my-4">Understanding where LLMs shine and where they stumble is essential for practical deployment.</p>

<h3 class="text-xl font-bold mt-10 mb-4">Genuine Strengths</h3>

<strong>First drafts and ideation.</strong> LLMs excel at generating starting points. First draft of a memo, brainstorming session, initial marketing copy—anywhere you need volume and variety to then refine, LLMs deliver.

<strong>Translation and transformation.</strong> Converting text from one format to another: summarizing long documents, translating between languages, converting bullet points to prose, reformatting data. These transformation tasks play to the model's core strengths.

<strong>Explanation and teaching.</strong> When you need complex concepts explained at different levels—"explain quantum computing to a 12-year-old" versus "explain it to a physics PhD student"—LLMs can flexibly adjust their communication style.

<strong>Code assistance.</strong> For writing boilerplate code, explaining existing code, suggesting debugging approaches, and automating routine programming tasks, LLMs have proven genuinely valuable.

<strong>Pattern recognition in text.</strong> Identifying themes across documents, extracting structured information from unstructured text, recognizing sentiment and intent—tasks that require understanding language at scale.

<h3 class="text-xl font-bold mt-10 mb-4">Fundamental Weaknesses</h3>

<strong>Mathematical reasoning.</strong> Despite appearing to perform calculations, LLMs frequently make arithmetic errors. They don't compute; they pattern-match. For anything requiring precise calculation, external tools are essential.

<strong>Factual accuracy.</strong> LLMs "hallucinate"—they generate confident-sounding statements that are simply false. They have no reliable mechanism for distinguishing what they know from what they're fabricating. This is perhaps their most dangerous failure mode.

<strong>Real-time information.</strong> Models are trained on historical data and have no knowledge of events after their training cutoff. They cannot check current stock prices, today's news, or whether a website is currently online.

<blockquote class="border-l-4 border-accent pl-6 py-2 my-8 text-xl italic text-gray-300"><strong>"The most dangerous aspect of LLMs isn't what they can't do—it's their tendency to confidently do things wrong."</strong></blockquote>

<strong>Complex multi-step reasoning.</strong> While LLMs can follow arguments and reproduce reasoning patterns, they struggle with genuinely novel logical challenges that require many interdependent steps.

<strong>Consistency across long contexts.</strong> Despite impressive context windows (GPT-4 can process over 100,000 tokens), models often lose track of information mentioned earlier in long documents or conversations.

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">The Stochastic Parrot Debate</h2>

<p class="text-gray-300 leading-relaxed my-4">In 2021, researchers Emily Bender, Timnit Gebru, and colleagues published a paper describing LLMs as "stochastic parrots"—systems that recombine patterns from their training data without genuine understanding. The term sparked fierce debate.</p>

<p class="text-gray-300 leading-relaxed my-4">The skeptic's position: LLMs are sophisticated autocomplete. They've memorized vast quantities of text and learned to remix it convincingly. But there's "nobody home"—no understanding, no reasoning, no meaning. The impressive outputs are a kind of statistical ventriloquism.</p>

<p class="text-gray-300 leading-relaxed my-4">The believer's position: Something significant is happening inside these models. They generalize beyond their training data, solve novel problems, and demonstrate capabilities that weren't explicitly taught. Even if the mechanism is different from human cognition, the functional capabilities are real.</p>

<p class="text-gray-300 leading-relaxed my-4">The honest answer: we don't fully know. There's genuine disagreement among experts about whether LLMs represent a meaningful step toward artificial general intelligence or a sophisticated dead end. What we can say is:</p>

<li class="ml-4">LLMs definitely don't think the way humans do</li>
<li class="ml-4">They definitely do something more complex than simple pattern matching</li>
<li class="ml-4">Their capabilities are real and useful regardless of the underlying mechanism</li>
<li class="ml-4">Their limitations are also real and require careful attention</li>

<p class="text-gray-300 leading-relaxed my-4">For business leaders, the philosophical question matters less than the practical one: what can these systems actually do for you, and where do they break down? The answer to that question is increasingly clear, even as the deeper questions about machine understanding remain unresolved.</p>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">Implications for Business Leaders</h2>

<p class="text-gray-300 leading-relaxed my-4">Understanding LLM fundamentals leads to several strategic implications:</p>

<h3 class="text-xl font-bold mt-10 mb-4">1. The Commoditization of Text Work</h3>

<p class="text-gray-300 leading-relaxed my-4">Any task that primarily involves transforming, generating, or analyzing text is now subject to AI automation. This doesn't mean humans become unnecessary—it means the premium shifts to judgment, creativity, and quality control rather than volume production. The writer who can edit LLM output into polished prose is more valuable than ever; the writer who competes with LLMs on first-draft speed is in trouble.</p>

<h3 class="text-xl font-bold mt-10 mb-4">2. The Verification Problem</h3>

<p class="text-gray-300 leading-relaxed my-4">Because LLMs hallucinate, any workflow involving them must include verification. This has organizational implications: you need people or systems that can check LLM outputs. For factual claims, this might mean automatic cross-referencing. For code, it means robust testing. For analysis, it means human review. Building these verification layers is essential for safe deployment.</p>

<h3 class="text-xl font-bold mt-10 mb-4">3. Prompt Engineering as a Core Skill</h3>

<p class="text-gray-300 leading-relaxed my-4">The same model can be extraordinarily useful or nearly useless depending on how you prompt it. Developing organizational capability in prompt engineering—knowing how to elicit the best outputs—is becoming a genuine competitive advantage. This isn't about tricks; it's about clearly communicating context, constraints, and expectations.</p>

<h3 class="text-xl font-bold mt-10 mb-4">4. The Speed of Capability Development</h3>

<p class="text-gray-300 leading-relaxed my-4">LLM capabilities are improving rapidly. What's impossible today may be routine in eighteen months. This argues for continuous experimentation and against over-investing in narrow use cases that might be superseded. Build flexible architectures; don't hard-code around current limitations.</p>

<h3 class="text-xl font-bold mt-10 mb-4">5. The Importance of Data Moats</h3>

<p class="text-gray-300 leading-relaxed my-4">LLMs are trained on public data. Your proprietary data—customer interactions, internal documents, specialized expertise—represents a genuine competitive advantage. Organizations that effectively integrate their unique data with LLM capabilities will outperform those that simply use off-the-shelf models.</p>

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">Key Takeaways</h2>

<strong>1. LLMs are prediction engines.</strong> At their core, they predict the next word in a sequence. The remarkable capabilities that emerge are byproducts of learning to predict accurately across billions of examples.

<strong>2. Scale creates qualitative change.</strong> Something unexpected happens when you train models on trillions of tokens with billions of parameters: capabilities emerge that weren't explicitly programmed and weren't present at smaller scales.

<strong>3. Training happens in three phases.</strong> Pre-training teaches language and knowledge. Fine-tuning teaches the model to be helpful. RLHF aligns the model with human preferences and values.

<strong>4. LLMs excel at transformation and generation.</strong> They're exceptional at first drafts, translation between formats, explanation, and code assistance. They struggle with math, factual accuracy, and complex reasoning.

<strong>5. Hallucination is a fundamental limitation.</strong> LLMs cannot reliably distinguish between what they know and what they're fabricating. Any serious deployment must include verification.

<strong>6. The philosophical questions are unresolved.</strong> Whether LLMs "understand" or merely mimic remains debated. For practical purposes, focus on what they can reliably do.

<strong>7. Organizational capabilities matter more than model access.</strong> Everyone has access to similar models. Competitive advantage comes from integration, verification, prompt engineering, and effective use of proprietary data.

<hr class="border-white/10 my-12">

<h2 class="text-2xl font-bold mt-12 mb-6">Further Reading</h2>

<ul class="list-disc list-inside space-y-2 my-4 text-gray-300"><li class="ml-4">OpenAI. "GPT-4 Technical Report." arXiv, 2023.</li>
<li class="ml-4">Anthropic. "Constitutional AI: Harmlessness from AI Feedback." 2022.</li>
<li class="ml-4">Google DeepMind. "Gemini: A Family of Highly Capable Multimodal Models." 2023.</li>
<li class="ml-4">Bender, Emily M., et al. "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" FAccT, 2021.</li>
<li class="ml-4">Wei, Jason, et al. "Emergent Abilities of Large Language Models." Transactions on Machine Learning Research, 2022.</li>
<p class="text-gray-300 leading-relaxed my-4"></ul></p>
<hr class="border-white/10 my-12">

<em>This article is part of the MASE Learn Fundamentals track. For the complete curriculum on AI literacy for business leaders, visit <a href="/learn" class="accent hover:underline">MASE Learn</a>.</em>

        </div>
    </article>

    <!-- Prev/Next Navigation -->
    
    <nav class="border-t border-white/10 py-8 px-6">
        <div class="max-w-4xl mx-auto flex justify-between">
            
            <a href="/learn/fundamentals/what-is-ai" class="group">
                <div class="text-sm text-gray-400 mb-1">Previous</div>
                <div class="text-lg font-bold group-hover:text-accent transition">What Is AI, Really?</div>
            </a>
            
            <div></div>
        </div>
    </nav>
    

    <!-- CTA -->
    <section class="py-16 px-6 border-t border-white/10">
        <div class="max-w-2xl mx-auto text-center">
            <h2 class="text-2xl font-bold mb-4">Need Help Implementing This?</h2>
            <p class="text-gray-400 mb-6">MASE Learn is free. If you need hands-on help with AI, that's what we do.</p>
            <a href="/#section-contact" class="btn-primary">Book a Strategy Session</a>
        </div>
    </section>

    <!-- Footer -->
    <footer class="border-t border-white/10 py-8 px-6">
        <div class="max-w-4xl mx-auto flex flex-col md:flex-row justify-between items-center gap-4">
            <div class="text-sm text-gray-500">2026 Mase Services LLC</div>
            <div class="flex items-center gap-6 text-sm text-gray-500">
                <a href="/" class="hover:text-white transition">Home</a>
                <a href="/research" class="hover:text-white transition">Research</a>
                <a href="/learn" class="hover:text-white transition">Learn</a>
            </div>
        </div>
    </footer>

    <script>lucide.createIcons();</script>
</body>
</html>